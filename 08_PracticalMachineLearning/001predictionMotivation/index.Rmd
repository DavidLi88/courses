---
title: "Practical Machine Learning Class Project"
author: "David Li"
date: "October 21, 2015"
output: 
  html_document:
    keep_md: true
---

## Background and Introduction

This is a homework assignment of Coursera’s Practical Machine Learning from Johns Hopkins University. Here is the introduction and requirement of the exercise:

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

The goal of my project is to predict the manner in which they did the exercise. This is the “classe” variable in the training set. I need to create a report describing how I built my model, how I used cross validation, what I think the expected out of sample error is, and why I made the choices I did. And I will also use my prediction model to predict 20 different test cases.

## Data Source

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project comes from this original source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment.


## Data Loading & Pre-processing

### Data Loading

Please Note that I download the data first from the links referenced above to my computer and upload the files into R (using RStudio).

```{r message=FALSE, warning=FALSE}
library("caret")
library("rpart")
library("randomForest")
library("rattle")

data.train <- read.csv("pml-training.csv", na.strings = c("","NA", "#DIV/0!"))
data.testcase <- read.csv("pml-testing.csv", na.strings = c("","NA", "#DIV/0!"))
dim(data.train)
str(data.train)

```


### Data Pre-processing

Some of variablea in the data set only have a single unique value or have only a handful of unique values that occur with very low frequencies. I built a variable deduction function to exclude those variable of which non-NA value less than 10% of the total observations. After the variable deduction, the final variables become 53 including "classe".
```{r, echo=TRUE}
isExcludeVar <- sapply(data.train, function (x) {sum(!is.na(x))/length(x) < 0.10})
data.train <- data.train[, !isExcludeVar]
data.train <- data.train[, -(1:7)]
dim(data.train)
str(data.train)

```

I split the data set into 70% training set & 30% testing set.
```{r}
set.seed(12345)
inTrain <- createDataPartition(y=data.train$classe, p=0.7, list=FALSE)
data.train.new <- data.train[inTrain,]
data.valid.new <- data.train[-inTrain,]
dim(data.train.new)
dim(data.valid.new)
```


## Prediction Model Selecting


### Decision Tree Model

I built a decision tree model for the training data set. The accuracy is only 0.722% for the testing data set
```{r}
modelFit1 <- rpart(classe ~ ., data=data.train.new, method="class")
fancyRpartPlot(modelFit1)

pred1 <- predict(modelFit1, data.valid.new, type = "class")
confusionMatrix(pred1, data.valid.new$classe)

```


### Random Forest Model

With decision tree model, the accuracy is only 0.722%, I need to try Random Forest model.
```{r}
set.seed(11111)
modFit2 <- randomForest(classe ~. , data=data.train.new, na.action = na.roughfix);
varImpPlot(modFit2)

pred2 <- predict(modFit2, newdata = data.valid.new)
confusionMatrix(pred2, data.valid.new$classe)

```

As we see, this yields a model that is roughly 99.24% predictive with a 95% confidence interval between 98.98% and 99.44%. This is the best choice.
The out of sample error on this model is 1-0.9924=0.0076.


## Prediction Assignment Submission

```{r}
answers <- predict(modFit2, newdata=data.testcase)
answers
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)

```
Predictions project submitted and 20 of 20 are correct.


## Conclusions and Observtions

The random forest appraoch with cross validation proved to perform very well for predicting activities from accelerometers measurements.


